{"nbformat_minor": 1, "cells": [{"execution_count": null, "cell_type": "code", "source": "%%info", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 1, "cell_type": "code", "source": "%%configure\n{\"conf\":{\"spark.jars.packages\": \"zhzhan:shc:0.0.11-1.6.1-s_2.10\"},\n\"jars\" :[\"local:///usr/hdp/current/hbase-client/lib/hbase-common.jar\",\n         \"local:///usr/hdp/current/hbase-client/lib/hbase-client.jar\",\n         \"local:///usr/hdp/current/hbase-client/lib/hbase-server.jar\",\n         \"local:///usr/hdp/current/hbase-client/lib/hbase-protocol.jar\",\n         \"local:///usr/hdp/current/hbase-client/lib/guava-12.0.1.jar\",\n         \"local:///usr/hdp/current/phoenix-client/phoenix-server.jar\"],\n\"files\":[\"wasb:///hbase-site.xml\"]}", "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "Current session configs: <tt>{u'files': [u'wasb:///hbase-site.xml'], u'jars': [u'local:///usr/hdp/current/hbase-client/lib/hbase-common.jar', u'local:///usr/hdp/current/hbase-client/lib/hbase-client.jar', u'local:///usr/hdp/current/hbase-client/lib/hbase-server.jar', u'local:///usr/hdp/current/hbase-client/lib/hbase-protocol.jar', u'local:///usr/hdp/current/hbase-client/lib/guava-12.0.1.jar', u'local:///usr/hdp/current/phoenix-client/phoenix-server.jar'], u'kind': 'spark', u'conf': {u'spark.jars.packages': u'zhzhan:shc:0.0.11-1.6.1-s_2.10'}}</tt><br>"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "No active sessions."}, "metadata": {}}], "metadata": {"collapsed": false}}, {"execution_count": 2, "cell_type": "code", "source": "import org.apache.spark.sql.{SQLContext, _}", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Creating SparkContext as 'sc'\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>13</td><td>application_1475691771944_0021</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-sparkc.0qtmk0rci3xuxiwjgrc3flwtqd.dx.internal.cloudapp.net:8088/proxy/application_1475691771944_0021/\">Link</a></td><td><a target=\"_blank\" href=\"http://172.30.0.11:30060/node/containerlogs/container_1475691771944_0021_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "Creating HiveContext as 'sqlContext'\nSparkContext and HiveContext created. Executing user code ...\nimport org.apache.spark.sql.{SQLContext, _}"}], "metadata": {"collapsed": false}}, {"execution_count": 3, "cell_type": "code", "source": "import org.apache.spark.sql.execution.datasources.hbase._", "outputs": [{"output_type": "stream", "name": "stdout", "text": "import org.apache.spark.sql.execution.datasources.hbase._"}], "metadata": {"collapsed": false}}, {"execution_count": 4, "cell_type": "code", "source": "import org.apache.spark.{SparkConf, SparkContext}", "outputs": [{"output_type": "stream", "name": "stdout", "text": "import org.apache.spark.{SparkConf, SparkContext}"}], "metadata": {"collapsed": false}}, {"execution_count": 5, "cell_type": "code", "source": "case class HBaseRecordAirline(col0: String,Year: Int,Quarter: Int,Month: Int,DayofMonth: Int,DayOfWeek: Int,FlightDate: Int,UniqueCarrier: String,AirlineID: String)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "defined class HBaseRecordAirline"}], "metadata": {"collapsed": false}}, {"execution_count": 6, "cell_type": "code", "source": "object HBaseRecordAirlineTest {def apply(i: Int): HBaseRecordAirline = {val s = s\"\"\"row${\"%03d\".format(i)}\"\"\" \n                                                                        HBaseRecordAirline(s,i,i,i,i,i,i,s,s)}}", "outputs": [{"output_type": "stream", "name": "stdout", "text": "defined module HBaseRecordAirlineTest"}], "metadata": {"collapsed": false}}, {"execution_count": 7, "cell_type": "code", "source": "val cat = s\"\"\"{\n     |             |\"table\":{\"namespace\":\"default\", \"name\":\"airdelaydata_scv_Test1\"},\n     |             |\"rowkey\":\"key\",\n     |             |\"columns\":{\n     |               |\"col0\":{\"cf\":\"rowkey\", \"col\":\"key\", \"type\":\"string\"},\n     |               |\"Year\":{\"cf\":\"Year\", \"col\":\"Year\", \"type\":\"int\"},\n     |               |\"Quarter\":{\"cf\":\"Quarter\", \"col\":\"Quarter\", \"type\":\"int\"},\n     |               |\"Month\":{\"cf\":\"Month\", \"col\":\"Month\", \"type\":\"int\"},\n     |               |\"DayofMonth\":{\"cf\":\"DayofMonth\", \"col\":\"DayofMonth\", \"type\":\"int\"},\n     |               |\"DayOfWeek\":{\"cf\":\"DayOfWeek\", \"col\":\"DayOfWeek\", \"type\":\"int\"},\n     |               |\"FlightDate\":{\"cf\":\"FlightDate\", \"col\":\"FlightDate\", \"type\":\"int\"},\n     |               |\"UniqueCarrier\":{\"cf\":\"UniqueCarrier\", \"col\":\"UniqueCarrier\", \"type\":\"string\"},\n     |               |\"AirlineID\":{\"cf\":\"AirlineID\", \"col\":\"AirlineID\", \"type\":\"string\"}\n     |             |}\n     |           |}\"\"\".stripMargin", "outputs": [{"output_type": "stream", "name": "stdout", "text": "cat: String = \n{\n\"table\":{\"namespace\":\"default\", \"name\":\"airdelaydata_scv_Test1\"},\n\"rowkey\":\"key\",\n\"columns\":{\n\"col0\":{\"cf\":\"rowkey\", \"col\":\"key\", \"type\":\"string\"},\n\"Year\":{\"cf\":\"Year\", \"col\":\"Year\", \"type\":\"int\"},\n\"Quarter\":{\"cf\":\"Quarter\", \"col\":\"Quarter\", \"type\":\"int\"},\n\"Month\":{\"cf\":\"Month\", \"col\":\"Month\", \"type\":\"int\"},\n\"DayofMonth\":{\"cf\":\"DayofMonth\", \"col\":\"DayofMonth\", \"type\":\"int\"},\n\"DayOfWeek\":{\"cf\":\"DayOfWeek\", \"col\":\"DayOfWeek\", \"type\":\"int\"},\n\"FlightDate\":{\"cf\":\"FlightDate\", \"col\":\"FlightDate\", \"type\":\"int\"},\n\"UniqueCarrier\":{\"cf\":\"UniqueCarrier\", \"col\":\"UniqueCarrier\", \"type\":\"string\"},\n\"AirlineID\":{\"cf\":\"AirlineID\", \"col\":\"AirlineID\", \"type\":\"string\"}\n}\n}"}], "metadata": {"collapsed": false}}, {"execution_count": 8, "cell_type": "code", "source": "val sparkConf = new SparkConf().setAppName(\"HBaseTestApp\")", "outputs": [{"output_type": "stream", "name": "stdout", "text": "sparkConf: org.apache.spark.SparkConf = org.apache.spark.SparkConf@6b9789d6"}], "metadata": {"collapsed": false}}, {"execution_count": 9, "cell_type": "code", "source": "import sqlContext.implicits._", "outputs": [{"output_type": "stream", "name": "stdout", "text": "import sqlContext.implicits._"}], "metadata": {"collapsed": false}}, {"execution_count": 10, "cell_type": "code", "source": "val data = (0 to 8).map { i =>HBaseRecordAirlineTest(i)}", "outputs": [{"output_type": "stream", "name": "stdout", "text": "data: scala.collection.immutable.IndexedSeq[HBaseRecordAirline] = Vector(HBaseRecordAirline(row000,0,0,0,0,0,0,row000,row000), HBaseRecordAirline(row001,1,1,1,1,1,1,row001,row001), HBaseRecordAirline(row002,2,2,2,2,2,2,row002,row002), HBaseRecordAirline(row003,3,3,3,3,3,3,row003,row003), HBaseRecordAirline(row004,4,4,4,4,4,4,row004,row004), HBaseRecordAirline(row005,5,5,5,5,5,5,row005,row005), HBaseRecordAirline(row006,6,6,6,6,6,6,row006,row006), HBaseRecordAirline(row007,7,7,7,7,7,7,row007,row007), HBaseRecordAirline(row008,8,8,8,8,8,8,row008,row008))"}], "metadata": {"collapsed": false}}, {"execution_count": 11, "cell_type": "code", "source": "sc.parallelize(data).toDF.write.options(Map(HBaseTableCatalog.tableCatalog -> cat, HBaseTableCatalog.newTable -> \"5\")).format(\"org.apache.spark.sql.execution.datasources.hbase\").save()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 12, "cell_type": "code", "source": "def withCatalog(cat: String): DataFrame = {\n     |       sqlContext\n     |         .read\n     |         .options(Map(HBaseTableCatalog.tableCatalog->cat))\n     |         .format(\"org.apache.spark.sql.execution.datasources.hbase\")\n     |         .load()\n     |     }", "outputs": [{"output_type": "stream", "name": "stdout", "text": "withCatalog: (cat: String)org.apache.spark.sql.DataFrame"}], "metadata": {"collapsed": false}}, {"execution_count": 13, "cell_type": "code", "source": "val df = withCatalog(cat)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "df: org.apache.spark.sql.DataFrame = [UniqueCarrier: string, Month: int, col0: string, Quarter: int, FlightDate: int, AirlineID: string, DayOfWeek: int, DayofMonth: int, Year: int]"}], "metadata": {"collapsed": false}}, {"execution_count": 14, "cell_type": "code", "source": "df.registerTempTable(\"table1\")", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 15, "cell_type": "code", "source": "val c = sqlContext.sql(\"select AirlineID from table1\")", "outputs": [{"output_type": "stream", "name": "stdout", "text": "c: org.apache.spark.sql.DataFrame = [AirlineID: string]"}], "metadata": {"collapsed": false}}, {"execution_count": 16, "cell_type": "code", "source": "c.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---------+\n|AirlineID|\n+---------+\n|   row000|\n|   row001|\n|   row002|\n|   row003|\n|   row004|\n|   row005|\n|   row006|\n|   row007|\n|   row008|\n+---------+"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}, "anaconda-cloud": {}}}